{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca65f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import csv\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import heapq\n",
    "from keras.models import load_model\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "    \"sys.path.insert(0,'/data/src/')\\n\",\n",
    "from data import LungDataset, blend, Pad, Crop, Resize\n",
    "from models import UNet, PretrainedUNet\n",
    "from metrics import jaccard, dice, auc, precision, recall, accuracy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The outputs of the models will be saved in resultFolder. \n",
    "resultFolder=\"/Users/esmasert/Desktop/PaperRelated/HeatMap/HeatmapInference/results/CV1/\"\n",
    "testImageFolder=\"/Users/esmasert/Desktop/LungTrainingCodes/Cross_Validation_Data_November-2024/only_cross_validation_test_files/CV1/test/img/\"\n",
    "resultCSVFile = \"/Users/esmasert/Desktop/PaperRelated/HeatMap/HeatmapInference/results/CV1/predictedPoints.csv\"\n",
    "\n",
    "    \"segmentationModelPath = \\\"/data/Segmentation/chosen_ckpts/unet-6v_18th_epoch_CV1.pt\\\"\\n\",\n",
    "heatMapModelPath = \"/Users/esmasert/Desktop/PaperRelated/HeatMap/HeatMapCrossValTrainingResults/chosen_models2/weights-improvement-17_CV1.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519af13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0,'/data/src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b3414",
   "metadata": {},
   "source": [
    "# Getting Ground Truth Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5aa23",
   "metadata": {},
   "source": [
    "## Concatenate CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcf372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0913e232470f>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfMain = dfMain.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "resultFolder=\"/data/HeatMap/HeatmapInference/results/CV1/\"\n",
    "testImageFolder=\"/data/Cross_Validation_Data_November-2024/only_cross_validation_test_files/CV1/test/img/\"\n",
    "resultCSVFile = \"/data/HeatMap/HeatmapInference/results/CV1/predictedPoints.csv\"\n",
    "\n",
    "segmentationModelPath = \"/data/Segmentation/chosen_ckpts/unet-6v_18th_epoch_CV1.pt\"\n",
    "heatMapModelPath = \"/data/HeatMap/HeatMapCrossValTrainingResults/chosen_models2/weights-improvement-17_CV1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bfe3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2535"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfMain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f89669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images:  445\n",
      "Number of test images that are found in csv files:  445\n"
     ]
    }
   ],
   "source": [
    "imgPoints=[]\n",
    "count=0\n",
    "\n",
    "for imageName in dfMain['image_name']:\n",
    "    #print(imageName)\n",
    "    res = any(imageName in imgname for imgname in test_files)\n",
    "    #print(res)\n",
    "    \n",
    "    if res == True :\n",
    "        count+=1\n",
    "\n",
    "print(\"Number of test images: \",len(test_files))\n",
    "print(\"Number of test images that are found in csv files: \",count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc23399",
   "metadata": {},
   "source": [
    "Some image files are not in csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64d767",
   "metadata": {},
   "source": [
    "## Get The Points of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc624eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPoints=[]\n",
    "for idx in range(0,len(dfMain)):\n",
    "    res = any(dfMain['image_name'][idx] in imgname for imgname in test_files)\n",
    "    if res == True :\n",
    "        tmp=[]\n",
    "        tmp.append(dfMain['image_name'][idx])\n",
    "        tmp.append(int(dfMain['ref_point_fst_lung'][idx].split(', ')[0].split('(')[-1]))\n",
    "        tmp.append(int(dfMain['ref_point_fst_lung'][idx].split(', ')[1].split(')')[0]))\n",
    "        tmp.append(int(dfMain['ref_point_snd_lung'][idx].split(', ')[0].split('(')[-1]))\n",
    "        tmp.append(int(dfMain['ref_point_snd_lung'][idx].split(', ')[1].split(')')[0]))\n",
    "        imgPoints.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb9c8ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851e0f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['146100695047215366253243105177291646230_yw3sa8', 153, 383, 375, 401]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgPoints[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852fb77",
   "metadata": {},
   "source": [
    "# Predict with The Segmentation and HeatMap Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d7132",
   "metadata": {},
   "source": [
    "We are going to predict the whole test data and saving the result points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eff04676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esmasert/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/esmasert/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "unet = PretrainedUNet(1, 2, True, \"bilinear\")\n",
    "index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e45656",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.load_state_dict(torch.load(segmentationModelPath, map_location=torch.device(\"cpu\")))\n",
    "unet.to(device)\n",
    "unet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['/data/CodesForCSVs/data/padchest_measurements.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42560ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, imgs, batch_size=1, shuffle=True):\n",
    "        self.imgs = imgs\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Get index of images to generate\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.__data_generation(indexes)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        #Shuffle the data after the generator has run through all samples\n",
    "        self.indexes = np.arange(len(self.imgs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def gaussian(self, xL, yL, H, W, sigma=5):\n",
    "        ##Function that creates the heatmaps##\n",
    "        channel = [math.exp(-((c - xL) ** 2 + (r - yL) ** 2) / (2 * sigma ** 2)) for r in range(H) for c in range(W)]\n",
    "        channel = np.array(channel, dtype=np.float32)\n",
    "        channel = np.reshape(channel, newshape=(H, W))\n",
    "\n",
    "        return channel\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples'\n",
    "        X_batch = [self.imgs for i in indexes]\n",
    "        X_batch = np.array(X_batch)\n",
    "\n",
    "        return X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d3f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    windowAreaList=[]\n",
    "    windowArea=0\n",
    "    \n",
    "    for x in range(0, image.shape[0]-windowSize, stepSize):\n",
    "        for y in range(0, image.shape[1]-windowSize, stepSize):\n",
    "            windowArea =0\n",
    "            for num1 in range(0,windowSize):\n",
    "                for num2 in range(0,windowSize):\n",
    "                    #print(image[x+num1][y+num2])\n",
    "                    windowArea+=image[x+num1][y+num2]\n",
    "                    \n",
    "            temp=[]\n",
    "            temp.append(windowArea)\n",
    "            temp.append(x)\n",
    "            temp.append(y)\n",
    "            \n",
    "            windowAreaList.append(temp)\n",
    "            \n",
    "    return windowAreaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0135101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideImageGetPoints(img):\n",
    "    \n",
    "    # Read the image\n",
    "    height, width = img.shape\n",
    "\n",
    "    # Cut the image in half\n",
    "    width_cutoff = width // 2\n",
    "    s1 = img[:, :width_cutoff]\n",
    "    s2 = img[:, width_cutoff:]\n",
    "    \n",
    "    wwindowSize=10\n",
    "    stepSize=5\n",
    "\n",
    "    windowsLeft = sliding_window(s1, stepSize, wwindowSize)\n",
    "    windowsRight = sliding_window(s2, stepSize, wwindowSize)\n",
    "                \n",
    "    #print(\"Len Windows Left:\", len(windowsLeft))\n",
    "    #print(\"Len Windows Right:\", len(windowsLeft))\n",
    "    #print(\"Len WindowSize:\", wwindowSize)\n",
    "\n",
    "    justWindowAreas=[]\n",
    "    for i in windowsLeft:\n",
    "        justWindowAreas.append(i[0])\n",
    "    largest2nums = heapq.nlargest(1, enumerate(justWindowAreas), key=lambda x: x[1])\n",
    "    #print(windowsLeft[largest2nums[0][0]])\n",
    "    point1=windowsLeft[largest2nums[0][0]][2],windowsLeft[largest2nums[0][0]][1]\n",
    "    cpoint1=int(point1[0]+(wwindowSize/2)),int(point1[1]+(wwindowSize/2))\n",
    "    \n",
    "    justWindowAreas=[]\n",
    "    for i in windowsRight:\n",
    "        justWindowAreas.append(i[0])\n",
    "    largest2nums = heapq.nlargest(1, enumerate(justWindowAreas), key=lambda x: x[1])\n",
    "    #print(windowsRight[largest2nums[0][0]])\n",
    "    point2=windowsRight[largest2nums[0][0]][2],windowsRight[largest2nums[0][0]][1]\n",
    "    cpoint2=int(point2[0]+(wwindowSize/2))+256,int(point2[1]+(wwindowSize/2))\n",
    "    \n",
    "    #print(\"Most intensive area centers: \",cpoint1,cpoint2)\n",
    "\n",
    "    return cpoint1,cpoint2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8530244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictModel(imagePath):\n",
    "    \n",
    "    origin = Image.open(imagePath).convert(\"P\")\n",
    "    origin = torchvision.transforms.functional.resize(origin, (512, 512))\n",
    "    origin = torchvision.transforms.functional.to_tensor(origin) - 0.5\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        origin = torch.stack([origin])\n",
    "        origin = origin.to(device)\n",
    "        out = unet(origin)\n",
    "        softmax = torch.nn.functional.log_softmax(out, dim=1)\n",
    "        out = torch.argmax(softmax, dim=1)\n",
    "\n",
    "        origin = origin[0].to(\"cpu\")\n",
    "        out = out[0].to(\"cpu\")\n",
    "        \n",
    "    pil_origin = torchvision.transforms.functional.to_pil_image(origin + 0.5).convert(\"RGB\")\n",
    "    \n",
    "    plt.imsave(resultFolder + \"PredictedSegmentation.jpg\" , out, cmap='gray')\n",
    "    img = cv2.imread(resultFolder + \"PredictedSegmentation.jpg\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    stringg=\"\"\n",
    "    for row in gray:\n",
    "        for itemIn in range(0,len(row)-1):\n",
    "            stringg+=str(row[itemIn])+\" \"\n",
    "        stringg+=str(row[itemIn+1])\n",
    "        stringg+=\"\\n\"      \n",
    "        \n",
    "    img = stringg.split()\n",
    "    img = ['0' if x == '' else x for x in img]\n",
    "\n",
    "    image_list = np.array(img,dtype = 'float')\n",
    "    X_train = image_list.reshape(512,512,1)\n",
    "    \n",
    "    #Testing to see if our DataGenerator is working\n",
    "    X_batch = next(DataGenerator(X_train).__iter__())\n",
    "    #print(X_batch.shape)\n",
    "\n",
    "    HeatMapPredictions = heatMapModel.predict(X_batch, verbose=0)\n",
    "    \n",
    "    HeatMapresultImage= HeatMapPredictions[1][index].sum(axis=2)\n",
    "    \n",
    "    cpoint1, cpoint2 = divideImageGetPoints(HeatMapresultImage)\n",
    "    \n",
    "    return cpoint1,cpoint2, HeatMapresultImage, X_batch, pil_origin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb300baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [59:55<00:00,  8.08s/it] \n"
     ]
    }
   ],
   "source": [
    "resultImgPoints=[]\n",
    "cnt=0\n",
    "\n",
    "for imPath in tqdm(test_files):\n",
    "    \n",
    "    cpoint1, cpoint2, HeatMapresultImage, X_batch, pil_origin = PredictModel(imPath)\n",
    "\n",
    "    justName = imPath.split(\"/\")[-1].split(\".\")[0]\n",
    "    #print(justName)\n",
    "    \n",
    "    tmp=[]\n",
    "    tmp.append(justName)\n",
    "    tmp.append(cpoint1[0])\n",
    "    tmp.append(cpoint1[1])\n",
    "    tmp.append(cpoint2[0])\n",
    "    tmp.append(cpoint2[1])\n",
    "    resultImgPoints.append(tmp)\n",
    "    \n",
    "    with open(resultCSVFile, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(tmp)\n",
    "        \n",
    "    # Turn interactive plotting off\n",
    "    plt.ioff()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(X_batch.reshape(512,512))\n",
    "    plt.plot(cpoint1[0], cpoint1[1], \"o\", markersize=10, color=\"red\")  # og:shorthand for green circle\n",
    "    plt.plot(cpoint2[0], cpoint2[1], \"o\", markersize=10, color=\"red\")  # og:shorthand for green circle\n",
    "    segName= resultFolder + justName + \"_seg_hm.png\"\n",
    "    plt.savefig(segName)\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    plt.imshow(pil_origin)\n",
    "    plt.plot(cpoint1[0], cpoint1[1], \"o\", markersize=10, color=\"red\")  # og:shorthand for green circle\n",
    "    plt.plot(cpoint2[0], cpoint2[1], \"o\", markersize=10, color=\"red\")  # og:shorthand for green circle\n",
    "    immName= resultFolder + justName + \"_org_hm.png\"\n",
    "    fig2.savefig(immName)\n",
    "    plt.close(fig2)\n",
    "    \n",
    "                 \n",
    "    cnt+=1\n",
    "    \n",
    "    #if cnt==80:\n",
    "    #    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08bed1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalError = 0\n",
    "icnt=0\n",
    "\n",
    "for gtimg in imgPoints:\n",
    "    for primg in resultImgPoints:\n",
    "        \n",
    "        if primg[0] == gtimg[0]:\n",
    "            \n",
    "            p1 = [gtimg[1], gtimg[2]]\n",
    "            q1 = [primg[1], primg[2]]\n",
    "            err1= math.dist(p1, q1)\n",
    "            \n",
    "            p2 = [gtimg[3], gtimg[4]]\n",
    "            q2 = [primg[3], primg[4]]\n",
    "            err2= math.dist(p2, q2)\n",
    "            \n",
    "            TotalError += err1\n",
    "            TotalError += err2\n",
    "            \n",
    "            icnt+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753c7b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f629f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorRate = (TotalError / (icnt*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "645a32b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04957721930650405"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ErrorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "068b673c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.957721930650405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ErrorRate * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef7fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
